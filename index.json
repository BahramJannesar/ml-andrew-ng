[
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/",
	"title": "دوره یادگیری ماشین دانشگاه استنفورد به فارسی",
	"tags": [],
	"description": "Andrew Ng دوره ماشین لرنینگ پروفسور",
	"content": "دوره یادگیری ماشین دانشگاه استنفورد تست\nفهرست مطالب  هفته اول     یادگیری ماشین چیست؟     یادگیری نظارتی چیست؟     یادگیری غیر نظارتی چیست؟     رگرسیون خطی با یک متغیر     تابع هزینه قسمت اول     تابع هزینه قسمت دوم     تابع هزینه قسمت سوم     گرادیان کاهشی قسمت اول     گرادیان کاهشی قسمت دوم     گرادیان کاهشی قسمت سوم      هفته دوم    رگرسیون خطی چند متغیره     گرادیان کاهشی چند متغیره     Feature Scaling     Debugging Gradient     رگرسیون چند جمله ای     معادله نرمال      هفته سوم    طبقه بندی     تابع هزینه     ساده شده تابع هزینه و گرادیان کاهشی     بهینه سازی پیشرفته      منابع مفید      حمایت     درباره      "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/",
	"title": "   هفته اول ",
	"tags": [],
	"description": "",
	"content": "تست\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/linear-regression-many-variable/",
	"title": "رگرسیون خطی چند متغیره",
	"tags": [],
	"description": "",
	"content": "توی این هفته قراره در مورد رگرسیون خطی با چندین متغیر صحبت کنیم!\nمثلا دیتا ای شبیه به این برای خانه ها را فرض کنید:\n   نماد      $m$ تعداد کل سطر های جدول داده ها   $n$ تعداد ویژگی ها یا همان متغیر ها   $x^{(i)}$ i امین ردیف از جدول شامل متغیر ها   $x_j^{(i)}$ مقدار موجود در ردیف i ام و ستون متغیر j    بنابراین برای تابع فرضه داریم: $h_\\theta = \\theta_0 + \\theta_1 + \\theta_2x + \u0026hellip; + \\theta_nx$\nبا مقدار پیشفرض برای $x_0$ که برابر با مقدار $1$ است.\nکه می‌توانیم برای محاسبه این مقدار از ضرب ترانهاده وکتور مقادیر تتا و وکتور x ها استفاده کنیم:\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/",
	"title": "یادگیری ماشین چیست؟",
	"tags": [],
	"description": "",
	"content": "دو تعریف از یادگیری ماشین ارائه شده است:\n Arthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.\n توجه: این یک تعریف قدیمی و غیر رسمی است!\n اما تعریفی مدرن تر \u0026hellip;\n Tom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.\n مثلا بازی چکرز!    نماد      E تجربه بار ها بازی کردن   T انجام بازی چکرز   P احتمال اینکه برنامه در بازی بعد برنده شود    به طور کلی هر مسئله یادگیری ماشین را میتوان به دو دسته نظارتی و غیر نظارتی تقسیم کرد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/",
	"title": " هفته دوم",
	"tags": [],
	"description": "",
	"content": "تست\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/",
	"title": " هفته سوم",
	"tags": [],
	"description": "",
	"content": "تست\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/useful-articles/",
	"title": "منابع مفید ",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/classification/",
	"title": "طبقه بندی",
	"tags": [],
	"description": "",
	"content": "Logistic Regresstion اینجا از مسائل Regression به مسائل Classification می‌رویم، اما با اسم Logistic Regression گیج نشوید! این اسم به دلایل تاریخی نامگذاری شده که در واقع رویکردی برای حل مسائل طبقه بندی است نه رگرسیون!\nBinary Classification به جای اینکه خروجی یعنی $y$ مقداری پیوسته در یک محدوده باشد، فقط $0$ یا $1$ است، یعنی : $ y \\in \\text{{0,1}} $\nبه طوری که معمولا به $0$، negative class و به $1$ هم positive class می‌گوییم، اما شما آزاد هستید که هر اسم دلخواهی را برای نام‌گذاری آن ها انتخاب کنید!\nفعلا فقط دو تا کلاس داریم که به این نوع از مسئله Binary Classification می‌گوییم.\nفرض کنید از رگرسیون خطی استفاده کنیم و نتیجه تمام پیش بینی های بیشتر از $0.5$ را به عنوان 1 در نظر بگیریم (نگاشت کنیم) ، و هم چنین تمام موارد کوچکتر از $0.5$ را $0$ در نظر بگیریم.\nآیا این متد برای مسائل طبقه بندی باینری خوب است؟\n  برای پاسخ کلیک کن   naghes\n  Hypothesis Representation تابع فرضیه ما باید به این شکل باشد:\n$$ h_\\theta(x) = g(\\theta^T x) \\hspace{2cm} 0 \\leqslant h_\\theta(x) \\leqslant 1 $$\n$$ g(z) = \\frac{1}{1 + e^{-z}} \\hspace{2cm} z = \\theta^Tx $$\nکه به این فرم جدید تابع سیگموئید یا تابع لجستیک می‌گوییم.\nکار با نمودار تعاملی تابع سیگموئید: http://desmos.com/calculator/bgontvxotm\n تابع $g(z)$ در اینجا اعداد حقیقی را به عددی بین $0$ و $1$ نگاشت می‌کند.\n$h_\\theta(x)$ به ما احتمال اینکه خروجی ما $1$ است را می‌دهد برای مثال $h_\\theta(x) = 0.7$ احتمال 70 درصدی را به ما می‌دهد که خروجی $1$ باشد.\nو احتمال اینکه پیش بینی ما در کلاس $0$ باشد متمم احتمال کلاس 0 است، که اینجا $\\text{30%} $ می‌شود.\n$$ h_\\theta(x) = P (y=1 | x;\\theta) = 1 - P (y = 0 | x;\\theta) $$ $$ P (y=0 | x;\\theta) + P (y=1 | x;\\theta) = 1 $$\nDecision Boundry برای مجزا کردن کلاس های $0$ و $1$ طبقه بندی باید خروجی تابع فرضیه را به این صورت تبدیل کنیم:\n$$ h_\\theta(x) \\geqslant 0.5 \\rightarrow y = 1 \\hspace{2cm} h_\\theta(x) \u0026lt; 0.5 \\rightarrow y = 0 $$\nنحوه عملکرد تابع لجستیکی $g$ ما به این صورت است که وقتی ورودی آن بزرگتر یا برابر صفر باشد، خروجی آن بزرگ تر یا مساوی $0.5$ می‌شود:\n$$ g(z) \\geqslant 0.5 $$ $$ \\text{ when } z \\geqslant 0 $$\nبه یاد داشته باشید که: $$z = 0, e^0 = 1 \\Rightarrow g(z) = \\frac{1}{2} $$ $$ z \\rightarrow \\infty, e^{-\\infty} \\rightarrow 0 \\Rightarrow g(z) = 1 $$ $$ z \\rightarrow -\\infty, e^{\\infty} \\rightarrow \\infty \\Rightarrow g(z) = 0 $$\nو اگر ورودی تابع g ،$ \\theta^T x $ باشد به این معنی است که:\n$$ h_\\theta(x) = g(\\theta^T x) \\geqslant 0.5 \\hspace{1.5cm} \\text{when } \\theta^T x \\geqslant 0 $$\nحالا می‌توانیم بگوییم که:\n$$ \\theta^T x \\geqslant 0 \\Rightarrow y = 1 \\hspace{1cm} \\theta^T x \u0026lt; 0 \\Rightarrow y = 0 $$\nخط تصمیم گیری، خطی است که قسمتی که 1=y است را از قسمت های 0=y جدا می‌کند، که این خط توسط تابع فرضیه ساخته می‌شود.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/gradient-many-variable/",
	"title": "گرادیان کاهشی چند متغیره",
	"tags": [],
	"description": "",
	"content": "الگوریتم جدید ما برای گرادیان کاهشی با چندین متغیر به این صورت است:\nو قسمت $ \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)} ) x_j^{(i)} $ همان مشتق جرئی $\\frac {\\partial} {\\partial\\theta_0} J(\\theta)$ است.\nبه طور مثال برای دو متغیره و یا بیشتر خواهیم داشت:\nیادآوری: مقدار $x_0$ برابر $1$ است.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/",
	"title": "یادگیری نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری نظارتی در یـادگـیری نــظارتـی یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده های لیبل خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.\nمسائل یادگیری نظارتی یا همان Supervised Learning به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.\nرگرسیون | Regression در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.\nدر مسئله پیش بینی قیمت خانه می‌خواهیم با مجموعه داده ای از قیمت های واقعی خانه ها بر اساس اندازه، قیمت خانه ای جدیدی را پیش بینی کنیم.\nطبقه بندی | Classification در عوض اینجا سعی می‌کنیم خروجی ای با مقدار گسسته پیش بینی کنیم. مثلا در مسئله تشخیص وخیم بودن یا نبودن سرطان می‌خواهیم بر اساس دو ویژگی سن و سایز تومور نتیجه را در یکی از دو دسته وخیم یا غیر وخیم طبقه بندی کنیم.\nمثال های بیشتری که شما پاسخ دهید!  با توجه به عکسی که از یک شخص دریافت کردید تشخیص دهید که سنش چه قدر است. می‌خواهید حساب های مشتری هارا بررسی کنید و تصمیم بگیرید که هک شده است یا نه. شما انبار بزرگی از اقلام یکسان دارید و می‌ خواهید پیش بینی کنید که طی 3 ماه آینده چه تعداد از این اقلام به فروش می رسند.    برای پاسخ مثال ها کلیک کن    Regression Classification Regression    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/sponsor/",
	"title": "حمایت",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/cost-function/",
	"title": "تابع هزینه",
	"tags": [],
	"description": "",
	"content": "ما نمی‌توانیم از همان تابعی هزینه ای که برای رگرسیون خطی استفاده کردیم، برای تابع لجستیک نیز استفاده کنیم، زیرا خروجی تابع لجستیک موج گونه است و باعث ایجاد تعداد زیادی مینیمم محلی می‌شود. به عبارت دیگر یک تابع محدب (convex) نیست.\nتابع هزینه ما برای Logistic Regression به این صورت است:\n$$ J(\\theta) = \\frac{1}{m} \\sum_{i = 1}^m Cost(h_\\theta(x^{(i)}, y^{(i)})) $$\n$$ Cost(h_\\theta(x), y) = -log(h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 1 $$\n$$ Cost(h_\\theta(x), y) = -log(1 - h_\\theta(x)) \\hspace{1cm} if \\hspace{0.3cm} y = 0 $$\nهرچه تابع فرضیه از $y$ دور تر باشد، خروجی تابع هزینه بزرگ تر است.\nو اگر تابع فرضیه برابر با $y$ باشد، هزینه ما $0$ است.\n$$ Cost(h_\\theta(x), y) = 0 \\hspace{0.3cm} if \\hspace{0.3cm} h_\\theta(x)) = y $$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 0 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 1$$\n$$ Cost(h_\\theta(x), y) \\rightarrow \\infty \\hspace{0.5cm} if \\hspace{0.3cm} y = 1 \\hspace{0.3cm} and \\hspace{0.3cm} h_\\theta(x) \\rightarrow 0 $$\nاگر پاسخ صحیح ما $y = 0$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما نیز $0$ شود.\nاگر فرضیه ما به $1$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nاگر پاسخ صحیح ما $y = 1$ باشد، سپس تابع هزینه $0$ خواهد شد، اگر خروجی تابع فرضیه ما $1$ شود.\nاگر فرضیه ما به $0$ میل کند، سپس تابع هزینه به بی نهایت میل می‌کند.\nبه خاطر داشته باشید که نوشتن تابع هزینه به این روش که $J(\\theta)$ برای رگرسیون لجستیک محدب است.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/info/",
	"title": "درباره ",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/feature-scaling/",
	"title": "Feature Scaling",
	"tags": [],
	"description": "",
	"content": "در این قسمت و قسمت بعدی در مورد فوت و فن هایی برای اعمال الگوریتم گرادیـــان کـــاهشی صحبت می‌کنیم.\nاگر شما مسئله ای دارید که چندین ویژگی یا متغیر دارد و اگر مطمئن هستید که متغیر ها در مقیاس مشابه ای نسبت به هم هستند، در این حــالت گرادیــــان کـــاهشی با سرعت بیشتری به همگرایی می‌رسد.\nفرض کنید مسئله ما دو متغیر به صورت زیر دارد: $$ x_1 = \\text {size(0-2000 feet^2) }$$ $$ x_2 = \\text {number of bedrooms(1-5) }$$\nکه اگر بـخواهیم نــــمودار کــــانتور را رسم کـنیم به این شکل خواهد شد. شکلی بلند و بیضی مــانند که گرادیـــان کـــاهشی بـرای پیدا کردن مینیمم کلی در این تابع هزینه زمان زیادی را باید صرف کند!\nکه اینجا از تکنیک Feature Scaling استفاده می‌کنیم!\nبرای انجام این کار باید مقدار متغیر $x$ را بر تفـــاضـل کران بالا و پایین خودش تقسیم کنیم. که با این کار مقادیر متغیر ها عددی بین $0$ و $1 $ قرار می‌گــیرد، و شکل معقول تری خـــواهیم داشــت. مثلا در این مسئله داریم:\n$$ x_1 = \\frac {\\text {size(feet^2)} } {2000}$$ $$ x_2 = \\frac {\\text {number of bedrooms} } {(5-1)}$$\nهمچنین روش مشابه دیگری برای انجام این کار به اسم mean normalization داریم. که در صورت کسر، تفاضل مقدار متغیر با میانگین همه مقادیر متغیر $x$ را قرار می‌دهیم.\n$$ x_i := \\frac{x_i - \\mu_i} {s_i} $$\nنکته: همچنین در مخرج کسر مـی‌توانیم از مــقدار انحراف معیار استفاده کنیم، که البته نتایج متفاوتی با هم دارند.\n "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/",
	"title": "یادگیری غیر نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری غیر نظارتی یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. Unsupervised Learning ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.\nخوشه بندی | Clustering در این مسـائـــل سـعــی مـی‌کــنیم داده هایی با ویژگی های مشترک را به چـندین گــروه تقـسیم کــنیم، یعنی آن ها را به خوشه ها تخصیص بدهیم. فرض کنید مجموعه داده از 1000000 ژن مختلف دارید و می‌خواهید راهی پیدا کنید که به صورت خودکار آن ها را گروه بندی کند که به نوعی به هم شباهت دارند.\nمثال های بیشتر \u0026hellip;\n دسته بندی مشتری های فروشگاه اینترنتی تا بتوانیم مشتری های مشابه را در یک خوشه نگه داری کنیم. الگوریتم Cocktail Party به شما امکان می‌دهد کـــه در مــحیط بــی نظم سـاختـار پیدا کنید:  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/simplified-cost-gradient/",
	"title": "ساده شده تابع هزینه و گرادیان کاهشی",
	"tags": [],
	"description": "",
	"content": "Cost Function ما می‌توانیم دو حالت شرطی تابع هزینه خودمان در قسمت قبلی را در یک حالت فشرده شده بنویسیم:\n$$ Cost(h_\\theta(x), y) = - y \\hspace{0.2cm} log(h_\\theta(x)) - (1 - y) log(1 - h_\\theta(x)) $$\nدر خاطر داشته باشید وقتی که $y$ برابر $1$ است، قسمت $(1 - y) log(1 - h_\\theta(x))$ برار $0$ خواهد شد.\nاگر $y$ برابر با $1$ باشد، سپس قسمت $- y \\hspace{0.2cm} log(h_\\theta(x))$ برابر $0$ خواهد شد و در نتیجه تاثیری ندارد.\nدر نهایت می‌توانیم کل تابه هزینه را به این صورت بنویسیم:\n$$ J(\\theta) = - \\frac{1}{m} \\sum_{i = 1}^m [y^{(i)} log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) log(1 - h_\\theta(x^{(i)})) ] $$\nو پیاده سازی برداری شده (vectorized) به این صورت خواهد بود:\n$$ \\begin{align*} \u0026amp; h = g(X\\theta)\\newline \u0026amp; J(\\theta) = \\frac{1}{m} \\cdot \\left(-y^{T}\\log(h)-(1-y)^{T}\\log(1-h)\\right) \\end{align*} $$\nGradient Descent به یاد داشته باشید که شکل کلی گرادیان کاهشی به این صورت است:\n$$ \\begin{align*}\u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\alpha \\dfrac{\\partial}{\\partial \\theta_j}J(\\theta) \\newline \u0026amp; \\rbrace\\end{align*} $$\nمی‌توانیم قسمت مشتق را با استفاده از حساب دیفرانسیل محاسبه کنیم:\n$$ \\begin{align*} \u0026amp; Repeat \\lbrace \\newline \u0026amp; \\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) x_j^{(i)} \\newline \u0026amp; \\rbrace \\end{align*} $$\nتوجه داشته باشید که این الگوریتم مشابه الگوریتمی است که ما در رگرسیون خطی استفاده کردیم، هنوز باید به صورت همزمان همه مقادیر $\\theta$ را به روز کنیم.\nو پیاده سازی برداری شده (vectorized) به این صورت خواهد بود:\n$$ \\theta := \\theta - \\frac{\\alpha}{m} X^T g((X \\theta) -\\vec{y} ) $$\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/debugging-gradient/",
	"title": "Debugging Gradient",
	"tags": [],
	"description": "",
	"content": "در این قسمت در مورد تکنیک هایی برای اطمینان از درستی کار گرادیان کاهشی صحبت مـی‌کنیم. و در ادامه در مورد نحوه انتخاب مقدار پارامتر آلفا.\nهمانطور که می‌دانیم کار گرادیان کاهشی پیدا کردن مقدار تتا برای ما است تا تابع هزینه مینیمم شود. می‌خواهیم نمودار تابع $J$ بر حسب دفعات انــــجام گرادیان کاهشی را رسم کنیم و تا متوجه بشویم که گرادیان کاهشی عملکرد درستی دارد یا نه!\nبه این ترتیب نموداری به این شکل خواهیم داشت: می‌بینیم که احتملا گرادیان کاهشی درست کار مـی‌کند چون بعد از هر بار انجام مقدار $J$ کاهش می‌یابد!\nهمـچنین مـی‌توانیم از Automatic convergence test استفاده کنیم، به این صورت که اگر $J$ بعد از هر تکرار کاهشی کمتر از $E= 10^{-3}$ داشته باشد، اعلام همگرایی می‌کنیم، که تعیین مقدار این آستانه سخت است!\nاگر چنین نموداری داشتیم یعنی گرادیان کـاهـشـی به درستی کار نمی‌کند:\nو معمولا به این معنی است که باید از مقدار آلفا کوچک تری استفاده کنیم.\nو در شکل زیر می‌بینیم که بزرگی بیش از حد آلفا باعث واگرایی شده است. که هیـچوقت به مینیمم نمی‌رسد!\nو گاهی اوقات نیز ممکن اسـت به شکل زیر باشد که باید مقدار آلفا را کاهش دهیم و اگر مقدار آلفا بیش از حد کوچک باشد، گرادیان کاهشی دیر تر به همگرایی می‌رسد.\nمتوجه می‌شویم که مقدار خوب برای آلفا مقداری است که در هر بار تکرار الگوریتم گرادیان کاهشی، تابع هزینه $J$ کاهش یابد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/",
	"title": "رگرسیون خطی با یک متغیر",
	"tags": [],
	"description": "",
	"content": "بررسی نماد ها و مفاهیم مثلا در دیتای خانه ها نماد ها به این صورت هستند:    نماد      $m$ تعداد کل ردیف های جدول دیتای یادگیری   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:\n$$(x_i, y_i) \\Rightarrow x_1= 2104, y_1 = 460$$\nاینجا منظور از $i$ اندیس دیتا در جدول است.\n همانطور که می‌بینید هدف ما اینکه با دادن مجموعه داده $train$ به الگوریتم، تابعی رو به وجود بیاوریم که با گرفتن متغیر ورودی $x$ متغیر خروجی یعنی $y$ رو پیش بینی کند! که به تابع $h$ ، $hypothesis$ یا فرضه می‌گوییم.\nتابع $h$ را به این شکل نمایش می‌‌دهیم: $$ h_\\theta(x) = \\theta_0 + \\theta_1x $$\nکه این در واقع رگرسیون خطی تک متغیره است، $x$ همان تک متغیر مدل است، $ \\theta_0, \\theta_1 $ نیز پارامتر های مدل هستند.\nخط قرمز همان تابع $h$ است که برای پیش بینی قیمت خانه با متغیر $x$ به دست آمده\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week3/advanced-optimization/",
	"title": "بهینه سازی پیشرفته",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/polynomial-regression/",
	"title": "رگرسیون چند جمله ای",
	"tags": [],
	"description": "",
	"content": "Polynomial Regression تابع فرضیه $h$ می‌تواند خطی نباشد، اگر تناسب خوبی با داده های ما ندارد، می‌توانیم برای تغییر منحنی تابع از توابع چند جمله ای استفاده کنیم تا به تناسب بهتری برای داده ها برسیم.\nفرض کنید که تابع فرضیه ما $ h_\\theta(x) = \\theta_0 + \\theta_1 x_1$ باشد بنابراین می‌توانیم ویژگی جدیدی بر پایه ویژگی $x_1$ اضافه کنیم تا به تابعی quadratic یا درجه دوم برسیم:\n$$ {\\color{Blue} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2}$$\nیا به تابعی درجه سه یا cubic: $$ {\\color{Green} h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_1^2 + \\theta_3 x_1^3}$$\nبه طور مثال برای تابع درجه سه می‌نویسیم:\nهمچنین می‌توانیم از نمودار ریشه دوم یا squaer root استفاده کنیم:\n$$ h_\\theta(x) = \\theta_0 + \\theta_1 x_1 + \\theta_2 \\sqrt{x}$$\nتوجه کنید بعد از اینکه ویژگی های جدید خود را به این روش اضافه کردید، انجام feature scaling برای برای ویژگی ها یا همان متغیر ها خیلی مهم است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/",
	"title": "تابع هزینه قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف تابع هزینه | Cost Function با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با انتخاب های متفاوت برای پارامتر های $\\theta_1$ و $\\theta_0$ تابع های فرضیه متفاوتی به دست می‌آوریم: در رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\\theta_0$ و $\\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.\nبنابراین مقادیر را باید طوری تعیین کنیم که خروجی تابع $h$ بر حسب $x$ تا جای ممکن به مقادیر واقعی $y$ در مجموعه دیتای آموزشی نزدیک باشد.\n$$ h_\\theta(x) = \\theta_0 + \\theta_1x $$ $$ J(\\theta_0,\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x) - y_i)^2 $$\nبنابراین تابع هزینه $J$ را به این صورت تعریف می‌کنیم. که تابع خطای مجذور نیز نامیده می‌شود، و هدف آن مینیمم کردن $\\theta_0$ و $\\theta_1$ است. دلیل حضور $\\frac{1}{2m}$ نیز برای این است که فرمول ریاضی آسان تر شود، با قرار دادن 2 در کسر یعنی عبارت را نصف می‌کنیم چون می‌دانیم که مینیمم کردن نصف چیزی مثل مینیمم کردن همان چیز است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/normal-equation/",
	"title": "معادله نرمال",
	"tags": [],
	"description": "",
	"content": "Normal Equation الگوریتم گرادیان کاهشی روشی بود برای مینیمم کردن تابع $J$ ، اما روش دومی نیز وجود دارد که بدون داشتن حلقه تکرار این کار را انجام بدهد که معادله نرمال نام دارد.\nفرض کنید که تابع هزینه درجه دو ای مثل این داریم: $$ J(\\theta) = a\\theta^2 + b\\theta + c $$ $$ \\frac{\\partial} {\\partial x} J(\\theta) \\overset{\\underset{\\mathrm{set}}{}}{=} 0 $$\nکه برای مینیمم کردن این تابع درجه دو مشتق آن را می‌گیریم و برابر با صفر قرار می‌دهیم، که این به ما اجازه می‌دهد که مقدار $\\theta$ را برای مینیمم کردن تابع پیدا کنیم.\nاما مسئله ای که برای ما جالب است $\\theta$ یک عدد حقیقی نیست، بلکه یک وکتور در ابعدا 1+n است:\nبرای محاسبه اینکه چطور تابع هزینه را مینیمم کنیم باید مشتق جزئی تابع $J$ را برای هر کدام از تتا ها بگیریم و برابر با صفر قرار دهیم، بعد از محاسبه همه معادله ها مقدار تتا ای که تابع $J$ مینیمم می‌شود را به دست می‌آوریم.\nاگر مجموعه آموزشی به این شکل داشته باشیم:\nمعادله نرمال ما برای محاسبه تتا به این صورت خواهد بود:\n$$ \\theta = (X^T X)^{-1} X^T y $$\nبا استفاده از معادله نرمال نیازی به Feature Scaling نداریم، و برای مقایسه گرادیان کاهشی و معادله نرمال:\n   گرادیان کاهشی معادله نرمال     به تنظیم پارامتر آلفا نیاز دارد به تنظیم پارامتر آلفا نیاز ندارد   به تکرار نیاز دارد به تکرار نیاز ندارد   مرتبه زمانی اش $O(kn)^3 $ است مرتبه زمانی اش $O(n)^3$ است   برای تعداد ویژگی های زیاد خوب کار می‌کند برای تعداد ویژگی های زیاد کند است    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/",
	"title": "تابع هزینه قسمت دوم",
	"tags": [],
	"description": "",
	"content": "تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:\nاما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\\theta(x) = \\theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم \u0026hellip;\nمثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:\n$$ {\\color{Red} J(\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_1x - y_i)^2 \\Rightarrow \\frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:\n$$ {\\color{Blue} J(0.5) = \\frac{1}{2m} [ (0.5 - 1)^2 + (1-2)^2 + (1.5 -3)^2] \\Rightarrow 0.58 } $$ $$ {\\color{Green} J(0) = \\frac{1}{2m} ( 1^2 + 2^2 + 3^2 +) \\Rightarrow 2.3 }$$\nو اگر به همین ترتیب برای مقادیر دیگر رسم کنیم:\nمتوجه می‌شویم که به ازای هر مقدار تتا به یک تابع فرضیه متفاوت و یک مقدار متفاوت برای تابع $J$ می‌رسیم و همینطور که می‌بینیم در نقطه $1$ در مینیمم ترین حالت ممکن هستیم و این همان هدف ما است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/",
	"title": "تابع هزینه قسمت سوم",
	"tags": [],
	"description": "",
	"content": "قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه، نمودار تابع هزینه یا همان $J$ به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به دیتای ما ممکن است به شکل زیر باشد:\nاما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!\nدر این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در $J$ بر حسب $\\theta_0$ و $\\theta_1$ های مختلف دارند.\nمثالی از یک نمودار کانتور:\nمثلا نقطه قرمز روی نمودار کانتور سمت راست برابر است با: $ \\theta_1 = -0.15, \\theta_0 = 800 $\nاما همینطور که می‌بینیم خط حاصل از تابع فرضیه تناسب خوبی با دیتا های ما ندارد! به این خاطر که نقطه ما از مینیمم که کوچکترین بیضی است خیلی دور است!\nدر این نقطه جدید هم کاملا مینیمم نیست اما خیلی بهتر از قبلی است. باز هم خط حاصل از تابع فرضیه بر حسب مقادیر انتخابی برای دو پارامتر مسئله با داده های ما متناسب نیست \u0026hellip;\nدر واقع ما به الگوریتمی نیاز داریم که برای ما مقادیر $\\theta_0$ و $\\theta_1$ را در حالتی که تابع $J$ مینیمم است بیابد.\nکه پاسخ ما گرادیان کاهشی یا همان Gradient Descent است !\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/",
	"title": "گرادیان کاهشی قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف گرادیان کاهشی | Gradient Descent گرادیان کاهشی را برای مینیمم کردن تابع هزینه $J$ استفاده می‌کنیم. اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین نیز استفاده می‌شود.\nمراحل کار به این شکل است:\nبا حدس های اولیه برای دو پارامتر $\\theta_0$ و $\\theta_1$ شروع می‌کنیم، مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.\nو سپس مقادیر $\\theta_0$ و $\\theta_1$ را به صورت جزئی تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به مینیمم کلی یا محلی برسیم.\nبرای درک بهتر فرض کنید موتور سواری هستید بر روی سطح شکل زیر و می‌خواهید به پایین ترین نقطه این سطح برسید!\nکه بسته به مقادیر پارامتر ها سفر خود را از یک نقطه بر روی این سطح شروع می‌کنید.\nشما در همه جهات میچرخید و اطرافتان را نگاه می‌کنید و سپس سعی می‌کنید مقدار کمی به پایین در یک جهت بروید و در سریع ترین زمان به پایین برسید. بنابراین به کدام جهت باید بروید ؟!\nاگر از بالاترین نقطه شکل زیر حرکت کنید به این نقطه نهایی در کف سطح می‌رسید.\nاما اگر نقطه شروع را کمی از سمت راست شروع کرده بودید مسیرتان به این شکل میشد.\nکه این ویژگی گرادیان کاهشی است!\nو اما این تعریف ریاضی الگوریتم گرادیان کاهشی است:\nقرار است به صورت مکرر این کار را ادامه بدهیم تا به نقطه مینیمم برسیم!، اما اجازه دهید با مثال موتور قضیه را باز کنیم!\nاینجا $\\alpha$ / آلفا یا همان نرخ یادگیری شبیه به گاز موتور ما است که تعیین می‌کند میزان بزرگی حرکت ما به پایین چه قدر باشد.\nعبارت مشتق $\\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) $ نیز برای ما شبیه به فرمان موتور است که تعیین کننده جهت حرکت خواهد بود.\nاما نکته ی دیگری نیز در گرادیان کاهشی وجود دارد تغییر مقدار $\\theta_0$ و $\\theta_1$ در هر بار در فرمول باید به صورت پیوسته انجام بشود!، یعنی ابتدا مقادیر حساب شود و سپس به مقادیر بعد از انجام محاسبه تغییر کند:\nاما به نظر شما کدام درست است ؟!\n  برای پاسخ کلیک کن   جواب درست شکل سمت جپ است، زیرا دو پارامتر هم زمان و پشت سر هم مقادیرشان تغییر می‌کند، درحالی که در شکل سمت راست ابتدا $\\theta_0$ تغییر می‌کند و بعد از آن در مرحله بعد برای محاسبه $\\theta_1$ از مقدار جدید و تغییر داده شده $\\theta_0$ استفاده می‌شود.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/",
	"title": "گرادیان کاهشی قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در قسمت قبل گرادیان کاهشی را به این صورت معرفی کردیم، در این قسمت می‌خواهیم به توضیح آلفا و عبارت مشتق بپردازیم. اما برای برای درک بهتر می‌خواهیم با یک مثال ساده تر تابعی با یک پارامتر را مینیمم کنیم، یعنی فرض می‌کنیم تابع هزینه $J$ فقط یک پارامتر دارد.\nتصور کنید تابع $J$ زیر را با پارامتر تتا یک در این نقطه داریم، و از این نقطه کارمان را شروع می‌کنیم.\nکاری که عبارت مشتق می‌کند این است که تانژانت این نقطه را می‌گیرد، مثل این خط قرمز که با تابع مماس است. پس از این عبارت شیب خط را به دست می‌آوریم و می‌بینیم که در اینجا شیب خط قرمز ما مثبت است، پس متوجه شدیم که در این شکل حاصل مشتق مثبت است، همچنین نرخ یادگیری نیز همیشه عددی مثبت است.\nبنابراین تغییر $\\theta$ طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (positive number)} $$\nبنابراین داریم $\\theta$ منهای مقداری مثبت که این باعث می‌شود $\\theta$ ما کاهش یابد و به سمت چپ برود!\nهمان چیزی که می‌خواهیم، نزدیک شدن به مینیمم!\nو اگر طبق مثال قبل از این نقطه جدید شروع کنیم شیب خط ما منفی خواهد شد، یعنی مشتق منفی!\nبنابراین تغییر تتا طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (negative number)} $$\nمی‌بینیم که داریم تتا یک منهای مقداری منفی که این باعث می‌شود تتا ما افزایش یابد و به سمت راست برود!\nدر شکل سمت چپ مقدار آلفا بسیار کوچک است که باعث می‌شود گرادیان کاهشی خیلی کند تر به مینیمم برسد یعنی نیاز داریم قدم های بیشتری به پایین برداریم.\nاما در شکل راست آلفا بسیار بزرگ تر است که باعث شده گرادیان کاهشی هیچ وقت به مینیمم نرسد. یعنی گرادیان کاهشی ما همگرا نیست بلکه واگرا است!\nحالا شما جواب بدید!\nچه اتفاقی می‌افتد اگر در شکل زیر پارامتر $\\theta_1$ در نقطه مینیمم باشد؟!\n  برای پاسخ کلیک کن   por kon :)\n  گرادیان نزولی به مینیمم موضعی ختم می‌شود حتی زمانی که نرخ یادگیری یا همان آلفا ثابت باشد!\nزیرا در هر بار انجام الگوریتم شیب خط حاصل از عبارت مشتق ملایم تر از حالت دفعه قبلش است و همینطور که به مینیمم نزدیک تر می‌شویم، مشتق نیز به صفر میل می‌کند. بنابراین هر بار مشتق کوچک تر می‌شود و این باعث می‌شود قدم ها هر بار کوچک تر و کوچک تر شوند. به این خاطر نیازی نیست در طول زمان مقدار آلفا را کاهش دهیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/",
	"title": "گرادیان کاهشی قسمت سوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت گرادیان کاهشی را با تابع هزینه ترکیب می‌کنیم و الگوریتم رگرسیون خطی را به دست می‌آوریم. تا اینجای کار به این ها رسیدیم:\nاینجا می‌خواهیم از گرادیان کاهشی برای مینیمم کردن تابع هزینه استفاده کنیم! ابتدا تابع $J$ را در الگوریتم گرادیان جاگذاری می‌کنیم و \u0026hellip;\nبا محاسبه عبارت مشتق جزئی در گرادیان کاهشی برای دو پارامتر $\\theta_0$ و $\\theta_1$ خواهیم داشت:\n$$ \\theta_0, j = 0: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) $$\n$$ \\theta_1, j = 1: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)} $$\nبه الگوریتم گرادیان کاهشی بر‌ می‌گردیم و جایگذاری، و در واقع به الگوریتم رگرسیون خطی می‌رسیم!\nدر قسمت اول گرادیان کاهشی در مثال موتور سوار دیدیم که بسته به اینکه از کجا شروع کنیم ممکن است که به مینیمم موضعی برسیم! اما تابع هزینه برای رگرسیون خطی همیشه تابعی سهمی مانند مثل این است:\nاین تابع محدب مینیمم موضعی ندارد، و فقط یک مینیمم کلی دارد. یعنی گرادیان کاهشی برای این تابع هزینه همیشه به نقطه بهینه می‌رسد! و بنابراین گرادیان نزولی را در عمل برای داده خانه ها به به این صورت می‌بینیم، که نتیجه تناسب خوبی دارد:\nو حالا می‌توانید از آن استفاده کنید تا قیمت خانه ها را برای دوستانتان پیشبینی کنید!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]
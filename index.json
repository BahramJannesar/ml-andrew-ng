[
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/",
	"title": "   هفته اول ",
	"tags": [],
	"description": "",
	"content": "تست\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/what-is-ml/",
	"title": "یادگیری ماشین چیست؟",
	"tags": [],
	"description": "",
	"content": "دو تعریف از یادگیری ماشین ارائه شده است:\n Arthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.\n توجه: این یک تعریف قدیمی و غیر رسمی است!\n اما تعریفی مدرن تر \u0026hellip;\n Tom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.\n مثلا بازی چکرز!    نماد      E تجربه بار ها بازی کردن   T انجام بازی چکرز   P احتمال اینکه برنامه در بازی بعد برنده شود    به طور کلی هر مسئله یادگیری ماشین را میتوان به دو دسته نظارتی و غیر نظارتی تقسیم کرد.\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/supervised/",
	"title": "یادگیری نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری نظارتی در یـادگـیری نــظارتـی یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده های لیبل خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.\nمسائل یادگیری نظارتی یا همان Supervised Learning به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.\nرگرسیون | Regression در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.\nدر مسئله پیش بینی قیمت خانه می‌خواهیم با مجموعه داده ای از قیمت های واقعی خانه ها بر اساس اندازه، قیمت خانه ای جدیدی را پیش بینی کنیم.\nطبقه بندی | Classification در عوض اینجا سعی می‌کنیم خروجی ای با مقدار گسسته پیش بینی کنیم. مثلا در مسئله تشخیص وخیم بودن یا نبودن سرطان می‌خواهیم بر اساس دو ویژگی سن و سایز تومور نتیجه را در یکی از دو دسته وخیم یا غیر وخیم طبقه بندی کنیم.\nمثال های بیشتری که شما پاسخ دهید!  با توجه به عکسی که از یک شخص دریافت کردید تشخیص دهید که سنش چه قدر است. می‌خواهید حساب های مشتری هارا بررسی کنید و تصمیم بگیرید که هک شده است یا نه. شما انبار بزرگی از اقلام یکسان دارید و می‌ خواهید پیش بینی کنید که طی 3 ماه آینده چه تعداد از این اقلام به فروش می رسند.    برای پاسخ مثال ها کلیک کن    Regression Classification Regression    "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/unsupervised/",
	"title": "یادگیری غیر نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری غیر نظارتی یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. Unsupervised Learning ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.\nخوشه بندی | Clustering در این مسـائـــل سـعــی مـی‌کــنیم داده هایی با ویژگی های مشترک را به چـندین گــروه تقـسیم کــنیم، یعنی آن ها را به خوشه ها تخصیص بدهیم. فرض کنید مجموعه داده از 1000000 ژن مختلف دارید و می‌خواهید راهی پیدا کنید که به صورت خودکار آن ها را گروه بندی کند که به نوعی به هم شباهت دارند.\nمثال های بیشتر \u0026hellip;\n دسته بندی مشتری های فروشگاه اینترنتی تا بتوانیم مشتری های مشابه را در یک خوشه نگه داری کنیم. الگوریتم Cocktail Party به شما امکان می‌دهد کـــه در مــحیط بــی نظم سـاختـار پیدا کنید:  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/linear-regression-one-variable/",
	"title": "رگرسیون خطی با یک متغیر",
	"tags": [],
	"description": "",
	"content": "بررسی نماد ها و مفاهیم مثلا در دیتای خانه ها نماد ها به این صورت هستند:    نماد      $m$ تعداد کل ردیف های جدول دیتای یادگیری   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:\n$$(x_i, y_i) \\Rightarrow x_1= 2104, y_1 = 460$$\nاینجا منظور از $i$ اندیس دیتا در جدول است.\n همانطور که می‌بینید هدف ما اینکه با دادن مجموعه داده $train$ به الگوریتم، تابعی رو به وجود بیاوریم که با گرفتن متغیر ورودی $x$ متغیر خروجی یعنی $y$ رو پیش بینی کند! که به تابع $h$ ، $hypothesis$ یا فرضه می‌گوییم.\nتابع $h$ را به این شکل نمایش می‌‌دهیم: $$ h_\\theta(x) = \\theta_0 + \\theta_1x $$\nکه این در واقع رگرسیون خطی تک متغیره است، $x$ همان تک متغیر مدل است، $ \\theta_0, \\theta_1 $ نیز پارامتر های مدل هستند.\nخط قرمز همان تابع $h$ است که برای پیش بینی قیمت خانه با متغیر $x$ به دست آمده\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost1/",
	"title": "تابع هزینه قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف تابع هزینه | Cost Function با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با انتخاب های متفاوت برای پارامتر های $\\theta_1$ و $\\theta_0$ تابع های فرضیه متفاوتی به دست می‌آوریم: در رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\\theta_0$ و $\\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.\nبنابراین مقادیر را باید طوری تعیین کنیم که خروجی تابع $h$ بر حسب $x$ تا جای ممکن به مقادیر واقعی $y$ در مجموعه دیتای آموزشی نزدیک باشد.\n$$ h_\\theta(x) = \\theta_0 + \\theta_1x $$ $$ J(\\theta_0,\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x) - y_i)^2 $$\nبنابراین تابع هزینه $J$ را به این صورت تعریف می‌کنیم. که تابع خطای مجذور نیز نامیده می‌شود، و هدف آن مینیمم کردن $\\theta_0$ و $\\theta_1$ است. دلیل حضور $\\frac{1}{2m}$ نیز برای این است که فرمول ریاضی آسان تر شود، با قرار دادن 2 در کسر یعنی عبارت را نصف می‌کنیم چون می‌دانیم که مینیمم کردن نصف چیزی مثل مینیمم کردن همان چیز است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost2/",
	"title": "تابع هزینه قسمت دوم",
	"tags": [],
	"description": "",
	"content": "تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:\nاما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\\theta(x) = \\theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم \u0026hellip;\nمثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:\n$$ {\\color{Red} J(\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_1x - y_i)^2 \\Rightarrow \\frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:\n$$ {\\color{Blue} J(0.5) = \\frac{1}{2m} [ (0.5 - 1)^2 + (1-2)^2 + (1.5 -3)^2] \\Rightarrow 0.58 } $$ $$ {\\color{Green} J(0) = \\frac{1}{2m} ( 1^2 + 2^2 + 3^2 +) \\Rightarrow 2.3 }$$\nو اگر به همین ترتیب برای مقادیر دیگر رسم کنیم:\nمتوجه می‌شویم که به ازای هر مقدار تتا به یک تابع فرضیه متفاوت و یک مقدار متفاوت برای تابع $J$ می‌رسیم و همینطور که می‌بینیم در نقطه $1$ در مینیمم ترین حالت ممکن هستیم و این همان هدف ما است!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/cost3/",
	"title": "تابع هزینه قسمت سوم",
	"tags": [],
	"description": "",
	"content": "قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه، نمودار تابع هزینه یا همان $J$ به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به دیتای ما ممکن است به شکل زیر باشد:\nاما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!\nدر این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در $J$ بر حسب $\\theta_0$ و $\\theta_1$ های مختلف دارند.\nمثالی از یک نمودار کانتور:\nمثلا نقطه قرمز روی نمودار کانتور سمت راست برابر است با: $ \\theta_1 = -0.15, \\theta_0 = 800 $\nاما همینطور که می‌بینیم خط حاصل از تابع فرضیه تناسب خوبی با دیتا های ما ندارد! به این خاطر که نقطه ما از مینیمم که کوچکترین بیضی است خیلی دور است!\nدر این نقطه جدید هم کاملا مینیمم نیست اما خیلی بهتر از قبلی است. باز هم خط حاصل از تابع فرضیه بر حسب مقادیر انتخابی برای دو پارامتر مسئله با داده های ما متناسب نیست \u0026hellip;\nدر واقع ما به الگوریتمی نیاز داریم که برای ما مقادیر $\\theta_0$ و $\\theta_1$ را در حالتی که تابع $J$ مینیمم است بیابد.\nکه پاسخ ما گرادیان کاهشی یا همان Gradient Descent است !\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient1/",
	"title": "گرادیان کاهشی قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف گرادیان کاهشی | Gradient Descent گرادیان کاهشی را برای مینیمم کردن تابع هزینه $J$ استفاده می‌کنیم. اما این الگوریتم تنها فقط در رگرسیون خطی کاربرد ندارد، بلکه در سایر قسمت های حوزه یادگیری ماشین نیز استفاده می‌شود.\nمراحل کار به این شکل است:\nبا حدس های اولیه برای دو پارامتر $\\theta_0$ و $\\theta_1$ شروع می‌کنیم، مثلا مقدار هر دو را در ابتدا $0$ تعیین می‌کنیم.\nو سپس مقادیر $\\theta_0$ و $\\theta_1$ را به صورت جزئی تغییر می‌دهیم تا تابع $J$ کاهش یابد، تا زمانی که به مینیمم کلی یا محلی برسیم.\nبرای درک بهتر فرض کنید موتور سواری هستید بر روی سطح شکل زیر و می‌خواهید به پایین ترین نقطه این سطح برسید!\nکه بسته به مقادیر پارامتر ها سفر خود را از یک نقطه بر روی این سطح شروع می‌کنید.\nشما در همه جهات میچرخید و اطرافتان را نگاه می‌کنید و سپس سعی می‌کنید مقدار کمی به پایین در یک جهت بروید و در سریع ترین زمان به پایین برسید. بنابراین به کدام جهت باید بروید ؟!\nاگر از بالاترین نقطه شکل زیر حرکت کنید به این نقطه نهایی در کف سطح می‌رسید.\nاما اگر نقطه شروع را کمی از سمت راست شروع کرده بودید مسیرتان به این شکل میشد.\nکه این ویژگی گرادیان کاهشی است!\nو اما این تعریف ریاضی الگوریتم گرادیان کاهشی است:\nقرار است به صورت مکرر این کار را ادامه بدهیم تا به نقطه مینیمم برسیم!، اما اجازه دهید با مثال موتور قضیه را باز کنیم!\nاینجا $\\alpha$ / آلفا یا همان نرخ یادگیری شبیه به گاز موتور ما است که تعیین می‌کند میزان بزرگی حرکت ما به پایین چه قدر باشد.\nعبارت مشتق $\\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) $ نیز برای ما شبیه به فرمان موتور است که تعیین کننده جهت حرکت خواهد بود.\nاما نکته ی دیگری نیز در گرادیان کاهشی وجود دارد تغییر مقدار $\\theta_0$ و $\\theta_1$ در هر بار در فرمول باید به صورت پیوسته انجام بشود!، یعنی ابتدا مقادیر حساب شود و سپس به مقادیر بعد از انجام محاسبه تغییر کند:\nاما به نظر شما کدام درست است ؟!\n  برای پاسخ کلیک کن   جواب درست شکل سمت جپ است، زیرا دو پارامتر هم زمان و پشت سر هم مقادیرشان تغییر می‌کند، درحالی که در شکل سمت راست ابتدا $\\theta_0$ تغییر می‌کند و بعد از آن در مرحله بعد برای محاسبه $\\theta_1$ از مقدار جدید و تغییر داده شده $\\theta_0$ استفاده می‌شود.\n  "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient2/",
	"title": "گرادیان کاهشی قسمت دوم",
	"tags": [],
	"description": "",
	"content": "در قسمت قبل گرادیان کاهشی را به این صورت معرفی کردیم، در این قسمت می‌خواهیم به توضیح آلفا و عبارت مشتق بپردازیم. اما برای برای درک بهتر می‌خواهیم با یک مثال ساده تر تابعی با یک پارامتر را مینیمم کنیم، یعنی فرض می‌کنیم تابع هزینه $J$ فقط یک پارامتر دارد.\nتصور کنید تابع $J$ زیر را با پارامتر تتا یک در این نقطه داریم، و از این نقطه کارمان را شروع می‌کنیم.\nکاری که عبارت مشتق می‌کند این است که تانژانت این نقطه را می‌گیرد، مثل این خط قرمز که با تابع مماس است. پس از این عبارت شیب خط را به دست می‌آوریم و می‌بینیم که در اینجا شیب خط قرمز ما مثبت است، پس متوجه شدیم که در این شکل حاصل مشتق مثبت است، همچنین نرخ یادگیری نیز همیشه عددی مثبت است.\nبنابراین تغییر $\\theta$ طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (positive number)} $$\nبنابراین داریم $\\theta$ منهای مقداری مثبت که این باعث می‌شود $\\theta$ ما کاهش یابد و به سمت چپ برود!\nهمان چیزی که می‌خواهیم، نزدیک شدن به مینیمم!\nو اگر طبق مثال قبل از این نقطه جدید شروع کنیم شیب خط ما منفی خواهد شد، یعنی مشتق منفی!\nبنابراین تغییر تتا طبق فرمول به این صورت است: $$ \\theta_1 := \\theta_1 - \\alpha \\text{ } \\cdot \\text{ (negative number)} $$\nمی‌بینیم که داریم تتا یک منهای مقداری منفی که این باعث می‌شود تتا ما افزایش یابد و به سمت راست برود!\nدر شکل سمت چپ مقدار آلفا بسیار کوچک است که باعث می‌شود گرادیان کاهشی خیلی کند تر به مینیمم برسد یعنی نیاز داریم قدم های بیشتری به پایین برداریم.\nاما در شکل راست آلفا بسیار بزرگ تر است که باعث شده گرادیان کاهشی هیچ وقت به مینیمم نرسد. یعنی گرادیان کاهشی ما همگرا نیست بلکه واگرا است!\nحالا شما جواب بدید!\nچه اتفاقی می‌افتد اگر در شکل زیر پارامتر $\\theta_1$ در نقطه مینیمم باشد؟!\n  برای پاسخ کلیک کن   por kon :)\n  گرادیان نزولی به مینیمم موضعی ختم می‌شود حتی زمانی که نرخ یادگیری یا همان آلفا ثابت باشد!\nزیرا در هر بار انجام الگوریتم شیب خط حاصل از عبارت مشتق ملایم تر از حالت دفعه قبلش است و همینطور که به مینیمم نزدیک تر می‌شویم، مشتق نیز به صفر میل می‌کند. بنابراین هر بار مشتق کوچک تر می‌شود و این باعث می‌شود قدم ها هر بار کوچک تر و کوچک تر شوند. به این خاطر نیازی نیست در طول زمان مقدار آلفا را کاهش دهیم!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week1/gradient3/",
	"title": "گرادیان کاهشی قسمت سوم",
	"tags": [],
	"description": "",
	"content": "در این قسمت گرادیان کاهشی را با تابع هزینه ترکیب می‌کنیم و الگوریتم رگرسیون خطی را به دست می‌آوریم. تا اینجای کار به این ها رسیدیم:\nاینجا می‌خواهیم از گرادیان کاهشی برای مینیمم کردن تابع هزینه استفاده کنیم! ابتدا تابع $J$ را در الگوریتم گرادیان جاگذاری می‌کنیم و \u0026hellip;\nبا محاسبه عبارت مشتق جزئی در گرادیان کاهشی برای دو پارامتر $\\theta_0$ و $\\theta_1$ خواهیم داشت:\n$$ \\theta_0, j = 0: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) $$\n$$ \\theta_1, j = 1: \\frac{\\partial}{\\partial \\theta_j} J(\\theta_0, \\theta_1) = \\frac{1}{m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)}) \\cdot x^{(i)} $$\nبه الگوریتم گرادیان کاهشی بر‌ می‌گردیم و جایگذاری، و در واقع به الگوریتم رگرسیون خطی می‌رسیم!\nدر قسمت اول گرادیان کاهشی در مثال موتور سوار دیدیم که بسته به اینکه از کجا شروع کنیم ممکن است که به مینیمم موضعی برسیم! اما تابع هزینه برای رگرسیون خطی همیشه تابعی سهمی مانند مثل این است:\nاین تابع محدب مینیمم موضعی ندارد، و فقط یک مینیمم کلی دارد. یعنی گرادیان کاهشی برای این تابع هزینه همیشه به نقطه بهینه می‌رسد! و بنابراین گرادیان نزولی را در عمل برای داده خانه ها به به این صورت می‌بینیم، که نتیجه تناسب خوبی دارد:\nو حالا می‌توانید از آن استفاده کنید تا قیمت خانه ها را برای دوستانتان پیشبینی کنید!\n"
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/",
	"title": "دوره یادگیری ماشین دانشگاه استنفورد به فارسی",
	"tags": [],
	"description": "Andrew Ng دوره ماشین لرنینگ پروفسور",
	"content": "دوره یادگیری ماشین دانشگاه استنفورد تست\nفهرست مطالب  هفته اول     یادگیری ماشین چیست؟     یادگیری نظارتی چیست؟     یادگیری غیر نظارتی چیست؟     رگرسیون خطی با یک متغیر     تابع هزینه قسمت اول     تابع هزینه قسمت دوم     تابع هزینه قسمت سوم     گرادیان کاهشی قسمت اول     گرادیان کاهشی قسمت دوم     گرادیان کاهشی قسمت سوم      هفته دوم     "
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/week2/",
	"title": " هفته دوم",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://mehrdad-dev.github.io/ml-andrew-ng/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]
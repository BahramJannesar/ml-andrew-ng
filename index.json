[
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/",
	"title": "   هفته اول ",
	"tags": [],
	"description": "",
	"content": "تست\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/what-is-ml/",
	"title": "یادگیری ماشین چیست؟",
	"tags": [],
	"description": "",
	"content": "دو تعریف از یادگیری ماشین ارائه شده است:\n Arthur Samuel: رشته مطالعاتی که به کامپیوتر ها این توانایی را می‌دهد که بدون برنامه نویسی صریح یاد بگیرند.\n توجه: این یک تعریف قدیمی و غیر رسمی است!\n اما تعریفی مدرن تر \u0026hellip;\n Tom Mitchell: به یک برنامه کامپیوتری گفته می‌شود که: برای یادگیری از تجربه E با توجه به برخی از وظایف به عنوان T و اندازه گیری عملکرد با P اگر عملکرد وظیفه T با استفاده از P اندازه گیری شود با استفاده از تجربه E بهبود یابد.\n مثلا بازی چکرز!    نماد      E تجربه بار ها بازی کردن   T انجام بازی چکرز   P احتمال اینکه برنامه در بازی بعد برنده شود    به طور کلی هر مسئله یادگیری ماشین را میتوان به دو دسته نظارتی و غیر نظارتی تقسیم کرد.\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/supervised/",
	"title": "یادگیری نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری نظارتی در یـادگـیری نــظارتـی یک مجموعه داده داریم و از قبل می‌دانیم که خروجی صحیح باید چطور باشد، اصطلاحا داده های لیبل خورده اند! با این ایده که به بین خروجی و ورودی رابطه وجود دارد.\nمسائل یادگیری نظارتی یا همان Supervised Learning به دو دسته رگرسیون و طبقه بندی تقسیم می‌شوند.\nرگرسیون | Regression در این مسائل سعی می‌کنیم خروجی ای با مقدار پیوسته را پیش بینی کنیم.\nدر مسئله پیش بینی قیمت خانه می‌خواهیم با مجموعه داده ای از قیمت های واقعی خانه ها بر اساس اندازه، قیمت خانه ای جدیدی را پیش بینی کنیم.\nطبقه بندی | Classification در عوض اینجا سعی می‌کنیم خروجی ای با مقدار گسسته پیش بینی کنیم. مثلا در مسئله تشخیص وخیم بودن یا نبودن سرطان می‌خواهیم بر اساس دو ویژگی سن و سایز تومور نتیجه را در یکی از دو دسته وخیم یا غیر وخیم طبقه بندی کنیم.\nمثال های بیشتری که شما پاسخ دهید!  با توجه به عکسی که از یک شخص دریافت کردید تشخیص دهید که سنش چه قدر است. می‌خواهید حساب های مشتری هارا بررسی کنید و تصمیم بگیرید که هک شده است یا نه. شما انبار بزرگی از اقلام یکسان دارید و می‌ خواهید پیش بینی کنید که طی 3 ماه آینده چه تعداد از این اقلام به فروش می رسند.    برای پاسخ مثال ها کلیک کن    Regression Classification Regression    "
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/unsupervised/",
	"title": "یادگیری غیر نظارتی چیست؟",
	"tags": [],
	"description": "",
	"content": "تعریف یادگیری غیر نظارتی یادگیری بدون نظارت این امکان را به ما مـی‌دهد کــه بدون داشتن هیچ ایده ای نسبت به خروجی داده ها به حل مشکلات نزدیک شویم. در واقع در اینجا داده های ما هیچ برچسبی نـدارنـد و الگوریتم‌ها به حال خود رها می‌شوند تا سـاختـارهــای موجود در میان داده‌ها را کشف کنند. Unsupervised Learning ها به دو دسته خوشه بندی و غیر خوشه بندی تقسیم می‌شوند.\nخوشه بندی | Clustering در این مسـائـــل سـعــی مـی‌کــنیم داده هایی با ویژگی های مشترک را به چـندین گــروه تقـسیم کــنیم، یعنی آن ها را به خوشه ها تخصیص بدهیم. فرض کنید مجموعه داده از 1000000 ژن مختلف دارید و می‌خواهید راهی پیدا کنید که به صورت خودکار آن ها را گروه بندی کند که به نوعی به هم شباهت دارند.\nمثال های بیشتر \u0026hellip;\n دسته بندی مشتری های فروشگاه اینترنتی تا بتوانیم مشتری های مشابه را در یک خوشه نگه داری کنیم. الگوریتم Party Cocktail به شما امکان می‌دهد کـــه در مــحیط بــی نظم سـاختـار پیدا کنید (غیر خوشه بندی)  "
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/linear-regression-one-variable/",
	"title": "رگرسیون خطی با یک متغیر",
	"tags": [],
	"description": "",
	"content": "بررسی نماد ها و مفاهیم مثلا در دیتای خانه ها نماد ها به این صورت هستند:\n   نماد      $m$ تعداد کل ردیف های جدول دیتای یادگیری   $x$ متغیر های ورودی   $y$ متغیر های خروجی یا هدف    برای آدرس دهی در جدول به این شکل عمل می‌کنیم:\n$$(x_i, y_i) \\Rightarrow x_1= 2104, y_1 = 460$$\nاینجا منظور از i اندیس دیتا در جدول است.\n همانظور که می‌بینید هدف ما اینکه با دادن مجموعه داده $train$ به الگوریتم، تابعی رو به وجود بیاوریم که با گرفتن متغیر ورودی $x$ متغیر خروجی یعنی $y$ رو پیش بینی کند! که به تابع $h$ ، $hypothesis$ یا فرضه می‌گوییم.\nتابع $h$ را به این شکل نمایش می‌‌دهیم: $$ h_\\theta(x) = \\theta_0 + \\theta_1x $$\nکه این در واقع رگرسیون خطی تک متغیره است، $x$ همان تک متغیر مدل است، $ \\theta_0, \\theta_1 $ نیز پارامتر های مدل هستند.\nخط قرمز همان تابع $h$ است که برای پیش بینی قیمت خانه با متغیر $x$ به دست آمده\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/cost1/",
	"title": "تابع هزینه قسمت اول",
	"tags": [],
	"description": "",
	"content": "تعریف تابع هزینه | Cost Function با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم. با این تابع می‌توانیم بهترین خط مستقیم را برای داده هایمان به دست آوریم.\nدر رگرسیون خطی مجموعه آموزشی مثل این نمودار داریم و می‌خواهیم مقادیری برای $\\theta_0$ و $\\theta_1$ به دست آوریم به طوری که خط راستی که رسم می‌کنیم، بهترین تطابق را با داده هایمان داشته باشد.\nبنابراین مقادیر را باید طوری تعیین کنیم که خروجی تابع $h$ بر حسب $x$ تا جای ممکن به مقادیر واقعی $y$ در مجموعه دیتای آموزشی نزدیک باشد.\n$$ h_\\theta(x) = \\theta_0 + \\theta_1x $$ $$ J(\\theta_0,\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\hat{y_i} - y_i)^2 = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\theta(x) - y_i)^2 $$\nبنابراین تابع هزینه $J$ را به این صورت تعریف می‌کنیم. که تابع خطای مجذور نیز نامیده می‌شود، و هدف آن مینیمم کردن $\\theta_0$ و $\\theta_1$ است. دلیل حضور $\\frac{1}{2m}$ نیز برای این است که فرمول ریاضی آسان تر شود، با قرار دادن 2 در کسر یعنی عبارت را نصف می‌کنیم چون می‌دانیم که مینیمم کردن نصف چیزی مثل مینیمم کردن همان چیز است!\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/cost2/",
	"title": "تابع هزینه قسمت دوم",
	"tags": [],
	"description": "",
	"content": "تا اینجا به طور خلاصه تمام چیزی که از تابع هزینه می‌دانیم در زیر آمده است:\nاما اجازه بدید برای ساده سازی تابع فرضیه را تنها با یک پارامتر به این شکل در نظر بگیریم: $ h_\\theta(x) = \\theta_1x $ و سه مقدار مختلف $0$، $5.0 $ و $1$ رو حساب کنیم \u0026hellip;\nمثلا برای مقدار تتا برابر با $1$ محاسبات زیر را خواهیم داشت:\n$$ {\\color{Red} J(\\theta_1) = \\frac{1}{2m} \\sum_{i=1}^{m} (\\theta_1x - y_i)^2 \\Rightarrow \\frac{1}{2m} (0^2 + 0^2 + 0^2) = 0 } $$ به همین صورت برای دو مقدار دیگر داریم:\n$$ {\\color{Blue} J(0.5) = \\frac{1}{2m} [ (0.5 - 1)^2 + (1-2)^2 + (1.5 -3)^2] \\Rightarrow 0.58 } $$ $$ {\\color{Green} J(0) = \\frac{1}{2m} ( 1^2 + 2^2 + 3^2 +) \\Rightarrow 2.3 }$$\nو اگر به همین ترتیب برای مقادیر دیگر رسم کنیم:\nمتوجه می‌شویم که به ازای هر مقدار تتا به یک تابع فرضیه متفاوت و یک مقدار متفاوت برای تابع $J$ می‌رسیم و همینطور که می‌بینیم در نقطه $1$ در مینیمم ترین حالت ممکن هستیم و این همان هدف ما است!\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week1/cost3/",
	"title": "تابع هزینه قسمت سوم",
	"tags": [],
	"description": "",
	"content": "قسمت قبل دیدیم که با داشتن فقط یک پارامتر برای تابع فرضیه، نمودار تابع هزینه یا همان J به صورت سهمی بود. اگر دو پارامتر داشته باشیم باز هم به صورت سهمی است، اما سه بعدی و بسته به دیتای ما ممکن است به شکل زیر باشد:\nاما ما برای نمایش این تابع از شکل سه بعدی استفاده نمی‌کنیم‌، بلکه از نمودار های کانتور استفاده می‌کنیم!\nدر این نمودار ها هر یک از بیضی ها نشان دهنده مجموعه ای از نقاط است که مقادیر یکسانی در J بر حسب تتا صفر و تتا یک های مختلف دارند.\nمثالی از یک نمودار کانتور:\nمثلا نقطه قرمز روی نمودار کانتور سمت راست برابر است با: $ \\theta_1 = -0.15, \\theta_0 = 800 $\nاما همینطور که می‌بینیم خط حاصل از تابع فرضیه تناسب خوبی با دیتا های ما ندارد! به این خاطر که نقطه ما از مینیمم که کوچکترین بیضی است خیلی دور است!\nدر این نقطه جدید هم کاملا مینیمم نیست اما خیلی بهتر از قبلی است. باز هم خط حاصل از تابع فرضیه بر حسب مقادیر انتخابی برای دو پارامتر مسئله با داده های ما متناسب نیست \u0026hellip;\nدر واقع ما به الگوریتمی نیاز داریم که برای ما مقادیر تتا صفر و تتا یک را در حالتی که تابع J مینیمم است بیابد.\nکه پاسخ ما گرادیان کاهشی یا همان Gradient Descent است !\n"
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/",
	"title": "هوش مصنوعی به فارسی",
	"tags": [],
	"description": "هر چیزی که در مورد هوش مصنوعی نیاز به دانستن است",
	"content": "دوره یادگیری ماشین دانشگاه استنفورد تست\nفهرست مطالب  هفته اول     یادگیری ماشین چیست؟     یادگیری نظارتی چیست؟     یادگیری غیر نظارتی چیست؟     رگرسیون خطی با یک متغیر     تابع هزینه قسمت اول     تابع هزینه قسمت دوم     تابع هزینه قسمت سوم      هفته دوم     "
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/week2/",
	"title": " هفته دوم",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://ai-eng.github.io/ml-andrew-ng/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]